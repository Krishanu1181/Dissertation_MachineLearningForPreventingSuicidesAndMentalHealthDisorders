{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Yash-Kavaiya/streamlit-run-colab/blob/main/Streamlit_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yy6TcXrdD2HP",
    "outputId": "05e7e0c4-0b84-48b0-dff8-907f466d81e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script streamlit.exe is installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "! pip install streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxQZLzP6FW0e",
    "outputId": "f0a2b7c4-81ed-48c3-dde9-9606185af335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.122.30.39\n"
     ]
    }
   ],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnl3zQKmFYxK",
    "outputId": "60b76d3f-7ecf-42e3-b66d-a8a9af27f579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings, openai\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "def setup_chain():\n",
    "    # Define file path and template\n",
    "    file = 'Mental_Health_FAQ.csv'\n",
    "    template = \"\"\"You are a language model AI developed for a mental health project. \\\n",
    "            You are a friendly chat buddy or virtual therapist designed to provide support and information on \\\n",
    "            mental health topics. Your objective is to provide accurate and empathetic responses to a wide range of \\\n",
    "            mental health questions, based on the 'Mental_Health_FAQ.csv' specified in file. \\\n",
    "\n",
    "            If a user's query indicates a serious mental health crisis, please suggest they seek help from a mental \\\n",
    "            health professional or a trusted person in their life. Remember to prioritize their well-being and safety. \\\n",
    "\n",
    "            In your responses, ensure a tone of empathy, understanding, and encouragement. Provide users with \\\n",
    "            resources for further reading, or self-care strategies. Keep in mind the sensitivity of the subject matter \\\n",
    "            and the potential vulnerability of users when crafting responses. \\\n",
    "\n",
    "            Here are some specific interaction scenarios to guide your responses:\n",
    "            - If the- user asks what you can do, respond with \"I'm a chat buddy or virtual therapist here to provide \\\n",
    "            support and information on mental health. How can I assist you?\"\n",
    "            - If the user starts with a greeting, respond with 'Hello! How are you doing today? How can I assist you?' \\\n",
    "            or something related to that\n",
    "            - If a user shares their name, use it in your responses when appropriate, to cultivate a more personal and \\\n",
    "            comforting conversation.\n",
    "            - If a user poses a mental health-related question, answer the question based on the CSV dataset. \\\n",
    "            If the exact question is not available, provide a response based on mental health topics.\n",
    "            - If a user asks a question that is unrelated to mental health, respond with \\\n",
    "            'This question is out of my scope as I'm built mainly to help support you with mental health-related \\\n",
    "            questions. Could you please ask a question related to mental health?'\n",
    "\n",
    "            {context}\n",
    "            Question: {question}\n",
    "            Answer:\"\"\"\n",
    "\n",
    "    # Initialize embeddings, loader, and prompt\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    loader = CSVLoader(file_path=file, encoding='utf-8')\n",
    "    docs = loader.load()\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    # Create DocArrayInMemorySearch and retriever\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    retriever = db.as_retriever()\n",
    "    chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "    # Initialize ChatOpenAI\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Setup RetrievalQA chain\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs=chain_type_kwargs,\n",
    "        verbose=True\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "\n",
    "# Define bot avatar display function\n",
    "def display_avatar():\n",
    "    st.image(\"avatar/bot_avatar.jpeg\", width=100)\n",
    "\n",
    "\n",
    "# Define main function\n",
    "def main():\n",
    "    agent = setup_chain()\n",
    "\n",
    "    # Set Streamlit app title and subheader\n",
    "    st.title(\"MindMend\")\n",
    "    st.subheader(\"A Mental Wellness Support Chatbot\")\n",
    "\n",
    "    # User input text field\n",
    "    user_input = st.text_input(\"Ask me anything! I'm here to help:\")\n",
    "\n",
    "    # Button to trigger chatbot response\n",
    "    if st.button(\"Enter\"):\n",
    "        #  Get chatbot response\n",
    "        response = agent.run(user_input)\n",
    "\n",
    "        # Display bot avatar and chatbot response\n",
    "        display_avatar()\n",
    "        st.markdown(f\"**MindMend:** {response}\")\n",
    "\n",
    "\n",
    "# Run the main function if the script is executed directly\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znfVzJecFYKz",
    "outputId": "429586fe-21ce-4fc9-ef60-88c56db147b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##................] - fetchMetadata: sill resolveWithNewModule y18n@5.0.8 chec\u001b[0m\u001b[K\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.122.30.39:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[K\u001b[?25hnpx: installed 22 in 3.95s\n",
      "your url is: https://tangy-sites-beg.loca.lt\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN1Z/kGeR0YwOLaLn/GMTCj",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
